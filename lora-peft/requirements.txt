# LoRA/PEFT Implementation Requirements
# Based on the checklist in fine-tuning/LoRA - PEFT.md

# Core dependencies
torch>=2.0.0
transformers>=4.30.0
datasets>=2.12.0
peft>=0.4.0
accelerate>=0.20.0
bitsandbytes>=0.39.0

# Additional utilities
scipy>=1.10.0
numpy>=1.24.0
evaluate>=0.4.0
tqdm>=4.65.0
wandb>=0.15.0

# Development and testing
pytest>=7.0.0
jupyter>=1.0.0
matplotlib>=3.7.0
seaborn>=0.12.0

# Optional for specific models
sentencepiece>=0.1.99
protobuf>=3.20.0
