# ğŸ¯ Multitask Fine-tuning Implementation

This project implements comprehensive Multitask Fine-tuning techniques based on the checklist in `fine-tuning/Multitask Fine-tuning.md`.

## ğŸ“‹ What is Multitask Fine-tuning?

Multitask Fine-tuning is a training paradigm that:
- **Trains a single model** on multiple tasks simultaneously
- **Shares knowledge** across related tasks for better generalization
- **Improves efficiency** by leveraging common representations
- **Enables zero-shot transfer** to new tasks

## ğŸ—ï¸ Architecture

```
Shared Backbone (BERT/T5/GPT)
         â†“
    Shared Encoder
         â†“
   Task-Specific Heads
    â†™    â†“    â†˜
Task A  Task B  Task C
(NLI)   (QA)   (Summ)
```

### Multitask vs Single-task Training

| Aspect | Single-task | Multitask |
|--------|-------------|-----------|
| Model Count | N models | 1 model |
| Training Time | N Ã— T | 1.2 Ã— T |
| Memory Usage | N Ã— M | 1 Ã— M |
| Knowledge Sharing | None | High |
| Zero-shot Transfer | Poor | Good |
| Task Interference | None | Possible |

## ğŸ“ Project Structure

```
multitask-fine-tuning/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ setup.py                    # Package setup
â”œâ”€â”€ config/                     # Configuration files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ multitask_config.py     # Multitask configurations
â”‚   â”œâ”€â”€ task_config.py          # Individual task configurations
â”‚   â””â”€â”€ training_config.py      # Training configurations
â”œâ”€â”€ multitask/                  # Core implementation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ multitask_model.py      # Main multitask model
â”‚   â”œâ”€â”€ task_heads.py           # Task-specific heads
â”‚   â”œâ”€â”€ data_manager.py         # Data management
â”‚   â””â”€â”€ loss_manager.py         # Loss balancing
â”œâ”€â”€ tasks/                      # Task implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ classification.py       # Text classification
â”‚   â”œâ”€â”€ question_answering.py   # Question answering
â”‚   â”œâ”€â”€ summarization.py        # Text summarization
â”‚   â”œâ”€â”€ named_entity_recognition.py # NER
â”‚   â””â”€â”€ natural_language_inference.py # NLI
â”œâ”€â”€ training/                   # Training systems
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ multitask_trainer.py    # Main trainer
â”‚   â”œâ”€â”€ sampling_strategies.py  # Data sampling
â”‚   â”œâ”€â”€ evaluation.py           # Evaluation utilities
â”‚   â””â”€â”€ callbacks.py            # Training callbacks
â”œâ”€â”€ data/                       # Data processing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py          # Data loading utilities
â”‚   â”œâ”€â”€ preprocessing.py        # Data preprocessing
â”‚   â””â”€â”€ task_datasets.py        # Task-specific datasets
â”œâ”€â”€ experiments/                # Experiment management
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ experiment_runner.py    # Experiment orchestration
â”‚   â”œâ”€â”€ hyperparameter_search.py # HPO
â”‚   â””â”€â”€ analysis.py             # Result analysis
â”œâ”€â”€ examples/                   # Example scripts
â”‚   â”œâ”€â”€ multitask_classification.py
â”‚   â”œâ”€â”€ multitask_qa_summarization.py
â”‚   â””â”€â”€ zero_shot_transfer.py
â””â”€â”€ notebooks/                  # Jupyter notebooks
    â”œâ”€â”€ 01_multitask_basics.ipynb
    â”œâ”€â”€ 02_task_interference_analysis.ipynb
    â””â”€â”€ 03_zero_shot_evaluation.ipynb
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Install the package
pip install -e .
```

### 2. Basic Multitask Training

```python
from multitask_fine_tuning import MultitaskModel, MultitaskTrainer
from config import MultitaskConfig, TaskConfig

# Define tasks
tasks = {
    "sentiment": TaskConfig(
        task_type="classification",
        num_labels=2,
        dataset_name="imdb"
    ),
    "nli": TaskConfig(
        task_type="classification", 
        num_labels=3,
        dataset_name="snli"
    ),
    "qa": TaskConfig(
        task_type="question_answering",
        dataset_name="squad"
    )
}

# Setup multitask configuration
config = MultitaskConfig(
    model_name_or_path="bert-base-uncased",
    tasks=tasks,
    task_sampling_strategy="proportional",
    loss_weighting_strategy="equal"
)

# Create multitask model
model = MultitaskModel(config)

# Train model
trainer = MultitaskTrainer(model, config)
trainer.train(train_datasets, eval_datasets)
```

### 3. Zero-shot Transfer

```python
# Load trained multitask model
model = MultitaskModel.from_pretrained("./multitask_model")

# Evaluate on new task without training
results = model.evaluate_zero_shot(
    task_name="new_task",
    test_dataset=new_task_dataset,
    task_type="classification"
)
```

## ğŸ”§ Key Features

### âœ… Multiple Task Types
- **Text Classification**: Sentiment, topic, intent classification
- **Question Answering**: Extractive and abstractive QA
- **Text Summarization**: Document and dialogue summarization
- **Named Entity Recognition**: Token-level classification
- **Natural Language Inference**: Textual entailment

### âœ… Flexible Architecture
- **Shared Backbone**: BERT, RoBERTa, T5, GPT models
- **Task-specific Heads**: Customizable output layers
- **Prompt-based Training**: Instruction-following paradigm
- **Adapter Integration**: Parameter-efficient multitask learning

### âœ… Advanced Training Strategies
- **Task Sampling**: Proportional, temperature-based, curriculum
- **Loss Balancing**: Equal weighting, uncertainty weighting, gradient-based
- **Data Mixing**: Batch-level and example-level mixing
- **Progressive Training**: Gradual task introduction

### âœ… Evaluation & Analysis
- **Per-task Metrics**: Task-specific evaluation
- **Transfer Analysis**: Positive/negative transfer measurement
- **Interference Detection**: Task conflict identification
- **Zero-shot Evaluation**: Generalization assessment

## ğŸ“Š Supported Tasks

### Text Classification
- Sentiment Analysis (IMDB, SST-2)
- Topic Classification (AG News, 20 Newsgroups)
- Intent Classification (ATIS, SNIPS)

### Question Answering
- Reading Comprehension (SQuAD, MS MARCO)
- Commonsense QA (CommonsenseQA, PIQA)
- Open-domain QA (Natural Questions)

### Text Generation
- Summarization (CNN/DailyMail, XSum)
- Dialogue Generation (PersonaChat)
- Data-to-text (WebNLG, E2E)

### Sequence Labeling
- Named Entity Recognition (CoNLL-2003)
- Part-of-speech Tagging (Penn Treebank)
- Chunking (CoNLL-2000)

## ğŸ§  Multitask Learning Principles

### 1. Shared Representations
```python
# Shared backbone processes all tasks
shared_features = backbone_model(input_text)

# Task-specific heads process shared features
task_a_output = task_a_head(shared_features)
task_b_output = task_b_head(shared_features)
task_c_output = task_c_head(shared_features)
```

### 2. Task Sampling Strategies
```python
# Proportional sampling (based on dataset size)
def proportional_sampling(datasets):
    total_size = sum(len(d) for d in datasets.values())
    probabilities = {task: len(d)/total_size for task, d in datasets.items()}
    return probabilities

# Temperature-based sampling (control task balance)
def temperature_sampling(datasets, temperature=1.0):
    sizes = [len(d) for d in datasets.values()]
    probs = softmax([s**temperature for s in sizes])
    return dict(zip(datasets.keys(), probs))
```

### 3. Loss Balancing
```python
# Uncertainty-based weighting
def uncertainty_weighting(task_losses, task_uncertainties):
    weights = {}
    for task in task_losses:
        # Higher uncertainty = lower weight
        weights[task] = 1.0 / (2 * task_uncertainties[task]**2)
    return weights

# Gradient-based balancing
def gradient_balancing(task_gradients):
    # Balance gradient magnitudes across tasks
    grad_norms = {task: torch.norm(grad) for task, grad in task_gradients.items()}
    weights = {task: 1.0 / norm for task, norm in grad_norms.items()}
    return weights
```

## ğŸ“ˆ Performance Benefits

### Knowledge Sharing
```
Single-task Training:
Task A: 85% accuracy (trained separately)
Task B: 82% accuracy (trained separately)  
Task C: 78% accuracy (trained separately)

Multitask Training:
Task A: 87% accuracy (+2% from shared knowledge)
Task B: 85% accuracy (+3% from shared knowledge)
Task C: 81% accuracy (+3% from shared knowledge)
```

### Resource Efficiency
```
Single-task Approach:
- Models: 3 separate models
- Training time: 3 Ã— T hours
- Memory: 3 Ã— M GB
- Storage: 3 Ã— S GB

Multitask Approach:
- Models: 1 shared model
- Training time: 1.2 Ã— T hours (20% overhead)
- Memory: 1 Ã— M GB
- Storage: 1 Ã— S GB
```

### Zero-shot Transfer
```
Multitask Model Performance on Unseen Tasks:
- Similar tasks: 70-85% of supervised performance
- Related tasks: 50-70% of supervised performance
- Distant tasks: 30-50% of supervised performance
```

## ğŸ”¬ Advanced Features

### Task Interference Mitigation
```python
# Gradient surgery to reduce negative transfer
def gradient_surgery(task_gradients, task_weights):
    # Project conflicting gradients
    for task_a, grad_a in task_gradients.items():
        for task_b, grad_b in task_gradients.items():
            if task_a != task_b:
                # Check for gradient conflict
                similarity = torch.cosine_similarity(grad_a, grad_b, dim=0)
                if similarity < 0:  # Conflicting gradients
                    # Project grad_a onto grad_b's orthogonal space
                    projection = torch.dot(grad_a, grad_b) / torch.dot(grad_b, grad_b) * grad_b
                    task_gradients[task_a] = grad_a - projection
    return task_gradients
```

### Curriculum Learning
```python
# Progressive task introduction
curriculum_schedule = {
    "phase_1": ["sentiment"],  # Start with simple task
    "phase_2": ["sentiment", "nli"],  # Add related task
    "phase_3": ["sentiment", "nli", "qa"]  # Add complex task
}
```

### Meta-learning Integration
```python
# MAML-style meta-learning for quick adaptation
def meta_learning_update(model, support_tasks, query_tasks):
    # Inner loop: adapt to support tasks
    adapted_params = model.adapt(support_tasks, num_steps=5)
    
    # Outer loop: optimize for query tasks
    meta_loss = model.compute_loss(query_tasks, adapted_params)
    return meta_loss
```

## ğŸ“– Documentation

See the `notebooks/` directory for detailed tutorials:
1. **Multitask Basics**: Understanding multitask learning
2. **Task Interference Analysis**: Analyzing positive/negative transfer
3. **Zero-shot Evaluation**: Evaluating generalization capabilities

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Implement your changes
4. Add tests and documentation
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- [T5 Paper](https://arxiv.org/abs/1910.10683)
- [MT-DNN Paper](https://arxiv.org/abs/1901.11504)
- [ExT5 Paper](https://arxiv.org/abs/2111.10952)
- [Hugging Face Transformers](https://huggingface.co/transformers/)
