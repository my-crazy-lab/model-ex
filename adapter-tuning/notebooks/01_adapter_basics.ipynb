{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”§ Adapter Tuning Basics\n",
    "\n",
    "This notebook introduces the basics of Adapter Tuning - a parameter-efficient fine-tuning method.\n",
    "\n",
    "## What is Adapter Tuning?\n",
    "\n",
    "Adapter Tuning inserts small neural network modules (adapters) into pre-trained models:\n",
    "- **Freezes** the original model parameters\n",
    "- **Trains** only the adapter parameters\n",
    "- **Achieves** comparable performance with much fewer parameters\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Original Layer: Input â†’ Transformer â†’ Output\n",
    "With Adapter:   Input â†’ Transformer â†’ Adapter â†’ Output\n",
    "```\n",
    "\n",
    "Each Adapter is a bottleneck module:\n",
    "```\n",
    "Input â†’ Down-projection â†’ Activation â†’ Up-projection â†’ Residual â†’ Output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install -r ../requirements.txt\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Import our adapter tuning modules\n",
    "from config import ModelConfig, AdapterConfig, TrainingConfig\n",
    "from adapters import AdapterModel, BottleneckAdapter\n",
    "from data import TextClassificationPreprocessor\n",
    "from training import AdapterTrainer\n",
    "from inference import AdapterInferencePipeline\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Adapter Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple adapter to understand the architecture\n",
    "input_size = 768  # BERT hidden size\n",
    "adapter_size = 64  # Bottleneck size\n",
    "\n",
    "adapter = BottleneckAdapter(\n",
    "    input_size=input_size,\n",
    "    adapter_size=adapter_size,\n",
    "    dropout=0.1,\n",
    "    activation=\"relu\"\n",
    ")\n",
    "\n",
    "print(\"Adapter Architecture:\")\n",
    "print(adapter)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in adapter.parameters())\n",
    "print(f\"\\nAdapter parameters: {total_params:,}\")\n",
    "print(f\"Compression ratio: {input_size / adapter_size:.1f}x\")\n",
    "\n",
    "# Test forward pass\n",
    "batch_size, seq_len = 2, 10\n",
    "dummy_input = torch.randn(batch_size, seq_len, input_size)\n",
    "\n",
    "output = adapter(dummy_input)\n",
    "print(f\"\\nInput shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Residual connection works: {torch.allclose(dummy_input + torch.zeros_like(dummy_input), output, atol=1e-3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Adapter Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for a small model (for demo)\n",
    "model_config = ModelConfig(\n",
    "    model_name_or_path=\"distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    max_length=128,\n",
    "    task_type=\"classification\"\n",
    ")\n",
    "\n",
    "adapter_config = AdapterConfig(\n",
    "    adapter_size=32,  # Small adapter for demo\n",
    "    adapter_dropout=0.1,\n",
    "    adapter_activation=\"relu\",\n",
    "    adapter_location=\"both\",  # Add to both attention and feedforward\n",
    "    freeze_base_model=True\n",
    ")\n",
    "\n",
    "# Create adapter model\n",
    "print(\"Creating adapter model...\")\n",
    "adapter_model = AdapterModel(model_config, adapter_config)\n",
    "\n",
    "# Print model information\n",
    "adapter_model.print_adapter_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small dataset for demo\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Take small subsets for quick demo\n",
    "train_dataset = dataset[\"train\"].select(range(100))\n",
    "eval_dataset = dataset[\"test\"].select(range(50))\n",
    "\n",
    "print(f\"Train examples: {len(train_dataset)}\")\n",
    "print(f\"Eval examples: {len(eval_dataset)}\")\n",
    "\n",
    "# Show example\n",
    "example = train_dataset[0]\n",
    "print(f\"\\nExample:\")\n",
    "print(f\"Text: {example['text'][:200]}...\")\n",
    "print(f\"Label: {example['label']} ({'Positive' if example['label'] == 1 else 'Negative'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quick Training Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training configuration\n",
    "training_config = TrainingConfig(\n",
    "    output_dir=\"./demo_results\",\n",
    "    num_train_epochs=1,  # Just 1 epoch for demo\n",
    "    per_device_train_batch_size=8,\n",
    "    learning_rate=2e-3,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"no\",  # Don't save for demo\n",
    "    freeze_base_model=True,\n",
    "    train_adapters_only=True\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = AdapterTrainer(\n",
    "    model_config=model_config,\n",
    "    adapter_config=adapter_config,\n",
    "    training_config=training_config,\n",
    "    task_type=\"classification\"\n",
    ")\n",
    "\n",
    "# Setup preprocessor\n",
    "adapter_model = trainer.setup_model()\n",
    "tokenizer = trainer.tokenizer\n",
    "\n",
    "preprocessor = TextClassificationPreprocessor(\n",
    "    tokenizer=tokenizer,\n",
    "    text_column=\"text\",\n",
    "    label_column=\"label\",\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "print(\"Starting quick training demo...\")\n",
    "train_result = trainer.train(\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    preprocessor=preprocessor\n",
    ")\n",
    "\n",
    "print(f\"Training completed!\")\n",
    "print(f\"Final loss: {train_result.training_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained adapter\n",
    "test_texts = [\n",
    "    \"This movie is absolutely fantastic!\",\n",
    "    \"Terrible movie, complete waste of time.\",\n",
    "    \"The movie was okay, nothing special.\",\n",
    "    \"Amazing acting and great storyline!\"\n",
    "]\n",
    "\n",
    "# Create inference pipeline\n",
    "inference_pipeline = AdapterInferencePipeline(\n",
    "    model_path=\"./demo_results\",\n",
    "    model_config=model_config,\n",
    "    adapter_config=adapter_config\n",
    ")\n",
    "\n",
    "# Get predictions\n",
    "predictions = inference_pipeline.classify_text(\n",
    "    test_texts,\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "print(\"Inference Results:\")\n",
    "for text, pred in zip(test_texts, predictions):\n",
    "    sentiment = \"Positive\" if pred[0][\"label\"] == \"LABEL_1\" else \"Negative\"\n",
    "    confidence = pred[0][\"score\"]\n",
    "    \n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Prediction: {sentiment} (confidence: {confidence:.3f})\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Adapter Efficiency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze adapter efficiency\n",
    "adapter_info = adapter_model.adapter_info\n",
    "\n",
    "print(\"Adapter Efficiency Analysis:\")\n",
    "print(f\"Total model parameters: {adapter_info['total_params']:,}\")\n",
    "print(f\"Base model parameters: {adapter_info['base_params']:,}\")\n",
    "print(f\"Adapter parameters: {adapter_info['total_adapter_params']:,}\")\n",
    "print(f\"Adapter percentage: {adapter_info['adapter_percentage']:.2f}%\")\n",
    "\n",
    "# Compare with full fine-tuning\n",
    "full_finetuning_params = adapter_info['total_params']\n",
    "adapter_params = adapter_info['total_adapter_params']\n",
    "reduction_factor = full_finetuning_params / adapter_params\n",
    "\n",
    "print(f\"\\nParameter Reduction:\")\n",
    "print(f\"Full fine-tuning would train: {full_finetuning_params:,} parameters\")\n",
    "print(f\"Adapter tuning trains only: {adapter_params:,} parameters\")\n",
    "print(f\"Reduction factor: {reduction_factor:.1f}x fewer parameters\")\n",
    "\n",
    "# Memory estimation\n",
    "bytes_per_param = 4  # float32\n",
    "full_memory_mb = (full_finetuning_params * bytes_per_param) / (1024 * 1024)\n",
    "adapter_memory_mb = (adapter_params * bytes_per_param) / (1024 * 1024)\n",
    "\n",
    "print(f\"\\nMemory Usage (approximate):\")\n",
    "print(f\"Full fine-tuning: {full_memory_mb:.1f} MB\")\n",
    "print(f\"Adapter tuning: {adapter_memory_mb:.1f} MB\")\n",
    "print(f\"Memory savings: {full_memory_mb - adapter_memory_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Adapter Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize adapter placement in the model\n",
    "def visualize_adapter_placement(adapter_model):\n",
    "    \"\"\"Visualize where adapters are placed in the model\"\"\"\n",
    "    \n",
    "    # Count adapters in each layer\n",
    "    adapter_counts = []\n",
    "    layer_names = []\n",
    "    \n",
    "    # Get encoder layers\n",
    "    if hasattr(adapter_model.base_model, 'distilbert'):\n",
    "        encoder = adapter_model.base_model.distilbert.transformer\n",
    "    elif hasattr(adapter_model.base_model, 'bert'):\n",
    "        encoder = adapter_model.base_model.bert.encoder\n",
    "    else:\n",
    "        print(\"Model architecture not supported for visualization\")\n",
    "        return\n",
    "    \n",
    "    for i, layer in enumerate(encoder.layer):\n",
    "        count = 0\n",
    "        if hasattr(layer, 'attention_adapter'):\n",
    "            count += 1\n",
    "        if hasattr(layer, 'feedforward_adapter'):\n",
    "            count += 1\n",
    "        \n",
    "        adapter_counts.append(count)\n",
    "        layer_names.append(f\"Layer {i}\")\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Bar plot of adapter counts\n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = plt.bar(layer_names, adapter_counts, color='skyblue', alpha=0.7)\n",
    "    plt.title('Adapters per Layer')\n",
    "    plt.xlabel('Transformer Layers')\n",
    "    plt.ylabel('Number of Adapters')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, adapter_counts):\n",
    "        if count > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n",
    "                    str(count), ha='center', va='bottom')\n",
    "    \n",
    "    # Pie chart of parameter distribution\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sizes = [adapter_info['base_params'], adapter_info['total_adapter_params']]\n",
    "    labels = ['Base Model', 'Adapters']\n",
    "    colors = ['lightcoral', 'skyblue']\n",
    "    \n",
    "    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Parameter Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Total layers: {len(layer_names)}\")\n",
    "    print(f\"Layers with adapters: {sum(1 for count in adapter_counts if count > 0)}\")\n",
    "    print(f\"Total adapters: {sum(adapter_counts)}\")\n",
    "\n",
    "# Create visualization\n",
    "visualize_adapter_placement(adapter_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "From this notebook, you learned:\n",
    "\n",
    "1. **Adapter Architecture**: Small bottleneck modules inserted into transformer layers\n",
    "2. **Parameter Efficiency**: Only 0.5-3% additional parameters needed\n",
    "3. **Training Process**: Freeze base model, train only adapters\n",
    "4. **Performance**: Comparable results to full fine-tuning\n",
    "5. **Memory Benefits**: Significant reduction in memory usage\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try different adapter sizes and configurations\n",
    "- Experiment with different tasks (NER, QA, etc.)\n",
    "- Explore multi-task learning with multiple adapters\n",
    "- Compare adapter methods (LoRA vs Adapters)\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Original Adapter Paper](https://arxiv.org/abs/1902.00751)\n",
    "- [AdapterHub](https://adapterhub.ml/)\n",
    "- [Parameter-Efficient Transfer Learning Survey](https://arxiv.org/abs/2106.04647)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
