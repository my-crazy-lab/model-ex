# âœ… Checklist há»c LoRA / PEFT (Parameter-Efficient Fine-Tuning)

## ğŸ“¦ 1. Chuáº©n bá»‹ mÃ´i trÆ°á»ng
- [ ] CÃ i Ä‘áº·t Python >= 3.8
- [ ] Táº¡o mÃ´i trÆ°á»ng áº£o (virtualenv hoáº·c conda)
- [ ] CÃ i Ä‘áº·t PyTorch (phiÃªn báº£n há»— trá»£ GPU)
- [ ] CÃ i cÃ¡c thÆ° viá»‡n chÃ­nh:
  - [ ] `transformers` (Hugging Face)
  - [ ] `datasets` (Hugging Face)
  - [ ] `peft` (Hugging Face PEFT library)
  - [ ] `accelerate` (tá»‘i Æ°u tá»‘c Ä‘á»™ train)
  - [ ] `bitsandbytes` (há»— trá»£ 8-bit, 4-bit)
  - [ ] `scipy`, `numpy`, `evaluate`, `tqdm`, `wandb` (tuá»³ chá»n)

## ğŸ“š 2. Chuáº©n bá»‹ dá»¯ liá»‡u
- [ ] Lá»±a chá»n táº­p dá»¯ liá»‡u phÃ¹ há»£p (vÃ­ dá»¥: tá»« Hugging Face Hub hoáº·c dá»¯ liá»‡u riÃªng)
- [ ] Tiá»n xá»­ lÃ½ dá»¯ liá»‡u:
  - [ ] Tokenization
  - [ ] Padding/Truncation
- [ ] Táº¡o `Dataset` train/validation

## ğŸ§  3. Chá»n mÃ´ hÃ¬nh ná»n (base model)
- [ ] Chá»n mÃ´ hÃ¬nh pre-trained (vÃ­ dá»¥: `bert-base-uncased`, `llama`, `mistral`, `falcon`, v.v.)
- [ ] Táº£i model vÃ  tokenizer tá»« `transformers`

## ğŸ§© 4. Cáº¥u hÃ¬nh PEFT / LoRA
- [ ] Chá»n phÆ°Æ¡ng phÃ¡p PEFT: `LoRA`, `Prefix-Tuning`, `Prompt-Tuning`, `IA3`
- [ ] Äá»‹nh nghÄ©a cáº¥u hÃ¬nh PEFT (`LoraConfig`, `PrefixTuningConfig`...)
- [ ] Ãp dá»¥ng cáº¥u hÃ¬nh vÃ o mÃ´ hÃ¬nh báº±ng `get_peft_model`

## ğŸš€ 5. Huáº¥n luyá»‡n mÃ´ hÃ¬nh
- [ ] Cáº¥u hÃ¬nh huáº¥n luyá»‡n (`TrainingArguments`, batch size, lr, epochs, v.v.)
- [ ] DÃ¹ng `Trainer` hoáº·c `Accelerate` Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh
- [ ] Theo dÃµi loss, eval metrics (tuá»³ chá»n: log báº±ng `wandb`)

## ğŸ’¾ 6. LÆ°u vÃ  kiá»ƒm tra mÃ´ hÃ¬nh
- [ ] LÆ°u mÃ´ hÃ¬nh PEFT Ä‘Ã£ fine-tune (`save_pretrained`)
- [ ] Load láº¡i vÃ  kiá»ƒm tra mÃ´ hÃ¬nh trÃªn táº­p test hoáº·c cÃ¢u há»i thá»±c táº¿

## ğŸ§ª 7. ÄÃ¡nh giÃ¡ & triá»ƒn khai
- [ ] ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t mÃ´ hÃ¬nh (accuracy, BLEU, F1, v.v.)
- [ ] So sÃ¡nh vá»›i mÃ´ hÃ¬nh gá»‘c hoáº·c fine-tune full
- [ ] Triá»ƒn khai inference báº±ng `pipeline` hoáº·c custom script

## ğŸ’¡ 8. TÃ¹y chá»n nÃ¢ng cao
- [ ] Sá»­ dá»¥ng quantization (4-bit, 8-bit) vá»›i `bitsandbytes`
- [ ] Káº¿t há»£p PEFT vá»›i QLoRA Ä‘á»ƒ tiáº¿t kiá»‡m hÆ¡n ná»¯a
- [ ] Thá»­ nghiá»‡m vá»›i nhiá»u mÃ´ hÃ¬nh vÃ  phÆ°Æ¡ng phÃ¡p PEFT khÃ¡c nhau
