# Model Compression & Quantization Requirements

# Core dependencies
torch>=2.0.0
transformers>=4.30.0
datasets>=2.12.0
evaluate>=0.4.0

# Quantization libraries
bitsandbytes>=0.41.0
optimum>=1.8.0

# Training and optimization
accelerate>=0.20.0
deepspeed>=0.9.0

# Scientific computing
numpy>=1.24.0
scipy>=1.10.0
scikit-learn>=1.3.0

# Model optimization
onnx>=1.12.0
onnxruntime>=1.15.0
onnxruntime-gpu>=1.15.0

# TensorRT (optional, for NVIDIA GPUs)
# tensorrt>=8.6.0
# pycuda>=2022.1

# Neural compression
neural-compressor>=2.0.0
torch-pruning>=1.2.0

# Memory profiling
psutil>=5.9.0
memory-profiler>=0.60.0
py3nvml>=0.2.7

# Utilities
tqdm>=4.65.0
pyyaml>=6.0
jsonlines>=3.1.0

# Visualization and monitoring
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.0.0
wandb>=0.15.0
tensorboard>=2.13.0

# Development and testing
pytest>=7.0.0
jupyter>=1.0.0
black>=22.0.0
flake8>=4.0.0

# Experiment tracking
mlflow>=2.0.0
optuna>=3.0.0

# Model serving
fastapi>=0.100.0
uvicorn>=0.22.0

# Additional utilities
pandas>=2.0.0
h5py>=3.8.0

# Mobile deployment
coremltools>=6.0.0  # For iOS deployment
tensorflow-lite>=2.13.0  # For Android deployment

# Benchmarking
benchmark-runner>=1.0.0
timm>=0.9.0  # For vision models

# Compression-specific
prune>=1.0.0
sparsity>=0.1.0
