{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”— Adapter Fusion Basics\n",
    "\n",
    "This notebook introduces the basics of Adapter Fusion - an advanced parameter-efficient fine-tuning method.\n",
    "\n",
    "## What is Adapter Fusion?\n",
    "\n",
    "Adapter Fusion combines knowledge from multiple task-specific adapters:\n",
    "- **Step 1**: Train individual adapters on different tasks\n",
    "- **Step 2**: Combine adapters using fusion mechanisms\n",
    "- **Step 3**: Enable knowledge transfer between tasks\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Base Model (Frozen)\n",
    "    â†“\n",
    "Task A Adapter â†’ \\\n",
    "Task B Adapter â†’ â†’ Fusion Layer â†’ Combined Output\n",
    "Task C Adapter â†’ /\n",
    "```\n",
    "\n",
    "## Benefits\n",
    "\n",
    "- **Knowledge Transfer**: Tasks learn from each other\n",
    "- **Parameter Efficiency**: Only fusion layer is added\n",
    "- **Modularity**: Easy to add/remove tasks\n",
    "- **No Catastrophic Forgetting**: Previous tasks are preserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install -r ../requirements.txt\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "\n",
    "# Import our fusion modules\n",
    "from config import ModelConfig, FusionConfig, TrainingConfig, AdapterConfig\n",
    "from fusion import FusionModel, AdapterManager, AttentionFusion, WeightedFusion\n",
    "from adapters import BottleneckAdapter\n",
    "from training import FusionTrainer\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Fusion Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy adapter outputs to understand fusion\n",
    "batch_size, seq_len, hidden_size = 2, 10, 768\n",
    "num_adapters = 3\n",
    "\n",
    "# Simulate outputs from 3 different adapters\n",
    "adapter_outputs = [\n",
    "    torch.randn(batch_size, seq_len, hidden_size),  # Sentiment adapter\n",
    "    torch.randn(batch_size, seq_len, hidden_size),  # NLI adapter  \n",
    "    torch.randn(batch_size, seq_len, hidden_size),  # QA adapter\n",
    "]\n",
    "\n",
    "print(f\"Number of adapters: {len(adapter_outputs)}\")\n",
    "print(f\"Each adapter output shape: {adapter_outputs[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Attention-based Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention fusion layer\n",
    "attention_fusion = AttentionFusion(\n",
    "    hidden_size=hidden_size,\n",
    "    num_adapters=num_adapters,\n",
    "    num_attention_heads=8,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "print(\"Attention Fusion Architecture:\")\n",
    "print(attention_fusion)\n",
    "\n",
    "# Test forward pass\n",
    "fused_output = attention_fusion(adapter_outputs)\n",
    "print(f\"\\nFused output shape: {fused_output.shape}\")\n",
    "\n",
    "# Count parameters\n",
    "fusion_params = sum(p.numel() for p in attention_fusion.parameters())\n",
    "print(f\"Fusion layer parameters: {fusion_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Weighted Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weighted fusion layer\n",
    "weighted_fusion = WeightedFusion(\n",
    "    hidden_size=hidden_size,\n",
    "    num_adapters=num_adapters,\n",
    "    learnable_weights=True,\n",
    "    weight_initialization=\"uniform\"\n",
    ")\n",
    "\n",
    "print(\"Weighted Fusion Architecture:\")\n",
    "print(weighted_fusion)\n",
    "\n",
    "# Test forward pass\n",
    "fused_output = weighted_fusion(adapter_outputs)\n",
    "print(f\"\\nFused output shape: {fused_output.shape}\")\n",
    "\n",
    "# Show learned weights\n",
    "weights = torch.softmax(weighted_fusion.fusion_weights, dim=0)\n",
    "print(f\"\\nLearned fusion weights: {weights.detach().numpy()}\")\n",
    "print(f\"Weight sum: {weights.sum().item():.3f}\")\n",
    "\n",
    "# Count parameters\n",
    "fusion_params = sum(p.numel() for p in weighted_fusion.parameters())\n",
    "print(f\"Fusion layer parameters: {fusion_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Individual Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adapter configurations for different tasks\n",
    "adapter_configs = {\n",
    "    \"sentiment\": AdapterConfig(\n",
    "        adapter_size=64,\n",
    "        task_name=\"sentiment\",\n",
    "        task_type=\"classification\"\n",
    "    ),\n",
    "    \"nli\": AdapterConfig(\n",
    "        adapter_size=64,\n",
    "        task_name=\"nli\", \n",
    "        task_type=\"classification\"\n",
    "    ),\n",
    "    \"qa\": AdapterConfig(\n",
    "        adapter_size=128,  # Larger adapter for complex QA task\n",
    "        task_name=\"qa\",\n",
    "        task_type=\"question_answering\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Create adapter manager\n",
    "adapter_manager = AdapterManager(\n",
    "    hidden_size=hidden_size,\n",
    "    adapter_configs=adapter_configs,\n",
    "    freeze_adapters=True  # Freeze for fusion training\n",
    ")\n",
    "\n",
    "print(\"Adapter Manager Information:\")\n",
    "adapter_manager.print_adapter_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Adapter Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test adapter manager with dummy input\n",
    "dummy_input = torch.randn(batch_size, seq_len, hidden_size)\n",
    "\n",
    "# Get outputs from all adapters\n",
    "all_outputs = adapter_manager(dummy_input)\n",
    "print(f\"Adapter outputs: {list(all_outputs.keys())}\")\n",
    "\n",
    "# Get outputs from specific adapters\n",
    "selected_outputs = adapter_manager(dummy_input, adapter_names=[\"sentiment\", \"nli\"])\n",
    "print(f\"Selected adapter outputs: {list(selected_outputs.keys())}\")\n",
    "\n",
    "# Check output shapes\n",
    "for name, output in all_outputs.items():\n",
    "    print(f\"{name} adapter output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Complete Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for fusion model\n",
    "model_config = ModelConfig(\n",
    "    model_name_or_path=\"distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    max_length=128,\n",
    "    multi_task=True,\n",
    "    task_names=list(adapter_configs.keys())\n",
    ")\n",
    "\n",
    "fusion_config = FusionConfig(\n",
    "    fusion_method=\"attention\",\n",
    "    num_attention_heads=8,\n",
    "    fusion_dropout=0.1,\n",
    "    freeze_adapters_during_fusion=True,\n",
    "    adapter_names=list(adapter_configs.keys())\n",
    ")\n",
    "\n",
    "# Create fusion model\n",
    "print(\"Creating fusion model...\")\n",
    "fusion_model = FusionModel(\n",
    "    model_config=model_config,\n",
    "    fusion_config=fusion_config,\n",
    "    adapter_manager=adapter_manager\n",
    ")\n",
    "\n",
    "# Print model information\n",
    "fusion_model.print_model_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Fusion Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_config.model_name_or_path)\n",
    "\n",
    "# Test texts\n",
    "test_texts = [\n",
    "    \"This movie is absolutely fantastic!\",\n",
    "    \"The film was terrible and boring.\",\n",
    "    \"An okay movie, nothing special.\"\n",
    "]\n",
    "\n",
    "fusion_model.eval()\n",
    "\n",
    "print(\"Testing Fusion Model Inference:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for text in test_texts:\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=model_config.max_length\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Test with different adapter combinations\n",
    "        outputs_sentiment = fusion_model(**inputs, adapter_names=[\"sentiment\"])\n",
    "        outputs_all = fusion_model(**inputs, adapter_names=list(adapter_configs.keys()))\n",
    "        \n",
    "        # Get probabilities\n",
    "        sentiment_probs = torch.softmax(outputs_sentiment.logits, dim=-1)\n",
    "        all_probs = torch.softmax(outputs_all.logits, dim=-1)\n",
    "        \n",
    "        print(f\"\\nText: '{text}'\")\n",
    "        print(f\"Sentiment only: {sentiment_probs[0].numpy()}\")\n",
    "        print(f\"All adapters: {all_probs[0].numpy()}\")\n",
    "        \n",
    "        # Prediction\n",
    "        pred_sentiment = \"Positive\" if sentiment_probs[0][1] > 0.5 else \"Negative\"\n",
    "        pred_all = \"Positive\" if all_probs[0][1] > 0.5 else \"Negative\"\n",
    "        \n",
    "        print(f\"Prediction (sentiment): {pred_sentiment}\")\n",
    "        print(f\"Prediction (fused): {pred_all}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fusion Efficiency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze fusion efficiency\n",
    "def analyze_model_efficiency(model):\n",
    "    \"\"\"Analyze model parameter efficiency\"\"\"\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    # Get component-wise parameters\n",
    "    base_params = sum(p.numel() for p in model.base_model.parameters())\n",
    "    adapter_params = sum(p.numel() for p in model.get_adapter_parameters())\n",
    "    fusion_params = sum(p.numel() for p in model.get_fusion_parameters())\n",
    "    \n",
    "    print(\"Model Efficiency Analysis:\")\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Trainable percentage: {trainable_params/total_params*100:.2f}%\")\n",
    "    print()\n",
    "    print(\"Component Breakdown:\")\n",
    "    print(f\"Base model: {base_params:,} ({base_params/total_params*100:.1f}%)\")\n",
    "    print(f\"Adapters: {adapter_params:,} ({adapter_params/total_params*100:.1f}%)\")\n",
    "    print(f\"Fusion layer: {fusion_params:,} ({fusion_params/total_params*100:.1f}%)\")\n",
    "    \n",
    "    # Compare with full fine-tuning\n",
    "    full_finetuning_params = base_params\n",
    "    fusion_overhead = adapter_params + fusion_params\n",
    "    reduction_factor = full_finetuning_params / fusion_overhead\n",
    "    \n",
    "    print()\n",
    "    print(\"Efficiency Comparison:\")\n",
    "    print(f\"Full fine-tuning would train: {full_finetuning_params:,} parameters\")\n",
    "    print(f\"Fusion approach trains: {fusion_overhead:,} parameters\")\n",
    "    print(f\"Parameter reduction: {reduction_factor:.1f}x fewer parameters\")\n",
    "    \n",
    "    return {\n",
    "        \"total_params\": total_params,\n",
    "        \"trainable_params\": trainable_params,\n",
    "        \"base_params\": base_params,\n",
    "        \"adapter_params\": adapter_params,\n",
    "        \"fusion_params\": fusion_params,\n",
    "        \"reduction_factor\": reduction_factor\n",
    "    }\n",
    "\n",
    "# Analyze our fusion model\n",
    "efficiency_stats = analyze_model_efficiency(fusion_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fusion Method Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different fusion methods\n",
    "fusion_methods = {\n",
    "    \"attention\": AttentionFusion(hidden_size, num_adapters, dropout=0.1),\n",
    "    \"weighted\": WeightedFusion(hidden_size, num_adapters, dropout=0.1),\n",
    "}\n",
    "\n",
    "print(\"Fusion Method Comparison:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for method_name, fusion_layer in fusion_methods.items():\n",
    "    # Count parameters\n",
    "    params = sum(p.numel() for p in fusion_layer.parameters())\n",
    "    \n",
    "    # Test forward pass\n",
    "    with torch.no_grad():\n",
    "        output = fusion_layer(adapter_outputs)\n",
    "    \n",
    "    print(f\"\\n{method_name.capitalize()} Fusion:\")\n",
    "    print(f\"  Parameters: {params:,}\")\n",
    "    print(f\"  Output shape: {output.shape}\")\n",
    "    print(f\"  Output mean: {output.mean().item():.4f}\")\n",
    "    print(f\"  Output std: {output.std().item():.4f}\")\n",
    "\n",
    "# Memory usage comparison\n",
    "print(\"\\nMemory Usage (approximate):\")\n",
    "bytes_per_param = 4  # float32\n",
    "\n",
    "for method_name, fusion_layer in fusion_methods.items():\n",
    "    params = sum(p.numel() for p in fusion_layer.parameters())\n",
    "    memory_mb = (params * bytes_per_param) / (1024 * 1024)\n",
    "    print(f\"{method_name.capitalize()}: {memory_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "From this notebook, you learned:\n",
    "\n",
    "1. **Fusion Architecture**: How to combine multiple adapters using different mechanisms\n",
    "2. **Attention Fusion**: Uses attention to learn optimal adapter combinations\n",
    "3. **Weighted Fusion**: Simple learnable weights for adapter combination\n",
    "4. **Parameter Efficiency**: Massive reduction in trainable parameters\n",
    "5. **Modularity**: Easy to add/remove adapters for different tasks\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try training individual adapters on real tasks\n",
    "- Experiment with different fusion methods\n",
    "- Test multi-task learning scenarios\n",
    "- Compare with traditional multi-task learning\n",
    "- Explore hierarchical fusion strategies\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [AdapterFusion Paper](https://arxiv.org/abs/2005.00247)\n",
    "- [Adapter-Hub](https://adapterhub.ml/)\n",
    "- [Parameter-Efficient Transfer Learning Survey](https://arxiv.org/abs/2106.04647)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
